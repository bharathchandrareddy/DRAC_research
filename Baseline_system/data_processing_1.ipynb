{"cells":[{"cell_type":"code","execution_count":null,"id":"6-9aghRyRi6K","metadata":{"executionInfo":{"elapsed":130,"status":"ok","timestamp":1714823419132,"user":{"displayName":"Yugandar Narra","userId":"14916928621674904417"},"user_tz":300},"id":"6-9aghRyRi6K"},"outputs":[],"source":["import pandas as pd\n","import os\n","import json\n","from shapely import wkt\n","from shapely.geometry import Polygon\n","from geopy.geocoders import Nominatim\n","from datetime import datetime\n","from tqdm import tqdm\n","from matplotlib import pyplot as plt\n","import seaborn as sns"]},{"cell_type":"code","execution_count":null,"id":"qY3KOnUwCGT8","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":628,"status":"ok","timestamp":1714823262352,"user":{"displayName":"Yugandar Narra","userId":"14916928621674904417"},"user_tz":300},"id":"qY3KOnUwCGT8","outputId":"385416a8-d9e1-4043-b52b-65d2482810f5"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"id":"bae181e5-2f0b-4d4c-9f7d-21771e2206fd","metadata":{"executionInfo":{"elapsed":127,"status":"ok","timestamp":1714823421736,"user":{"displayName":"Yugandar Narra","userId":"14916928621674904417"},"user_tz":300},"id":"bae181e5-2f0b-4d4c-9f7d-21771e2206fd"},"outputs":[],"source":["# Define location of the images and labels\n","xbd_dir=\"C:\\\\Users\\\\PC\\\\Desktop\\\\damage_assessement_data\\\\train\"\n","images_dir=os.path.join(xbd_dir,\"images\")\n","labels_dir=os.path.join(xbd_dir,\"labels\")\n","masks_dir = os.path.join(xbd_dir, 'masks')\n","if not os.path.isdir(masks_dir):\n","    os.makedirs(masks_dir)\n","extracted_files = 'C:\\\\Users\\\\PC\\\\Desktop\\\\drac_saved_files'\n","train_data_info=os.path.join(xbd_dir,\"train_data_info1.csv\")"]},{"cell_type":"code","execution_count":null,"id":"10120f2a-b57b-4029-b49a-94492c676c78","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":416538,"status":"ok","timestamp":1714823896009,"user":{"displayName":"Yugandar Narra","userId":"14916928621674904417"},"user_tz":300},"id":"10120f2a-b57b-4029-b49a-94492c676c78","outputId":"42f93d7b-2cc2-44c3-cffc-92b407023e89"},"outputs":[],"source":["# Dont run if csv file is already created\n","#Create Dataframe\n","columns = ['pre_image_name', 'post_image_name', 'disaster_name', 'disaster_type',\n","           'disaster_location', 'num_buildings_pre', 'num_buildings_post',\n","           'num_no_damage', 'num_minor_damage', 'num_major_damage',\n","           'num_destroyed', 'num_un_classified','pre_disaster_capture_date','post_disaster_capture_date']\n","df = pd.DataFrame(columns=columns)\n","# Fetch values from json labels and enter into dataframe\n","# Dictionary to fill location for labels with missing buildings\n","disaster_location_info={}\n","# iterate through all labels files\n","for json_filename in tqdm(os.listdir(labels_dir)):\n","    # only process pre disaster json files\n","    if json_filename.endswith('.json') and \"_pre\" in json_filename:\n","        disaster_location=\"\"\n","        # read json file\n","        pre_json_filepath=os.path.join(labels_dir,json_filename)\n","        # set post disaster json file name\n","        post_json_filepath = os.path.join(labels_dir, json_filename.replace(\"_pre\", \"_post\"))\n","        # check if post disaster json file exists and skip considering current json file if post json doesn't exist\n","        if not os.path.exists(post_json_filepath):\n","            continue\n","        # read pre-disaster json\n","        with open(pre_json_filepath, 'r') as file:\n","            pre_data = json.load(file)\n","            # fetch pre-disaster image name from metadata\n","            pre_image_name=pre_data[\"metadata\"][\"img_name\"]\n","            # fetch disaster event name from metadata\n","            disaster_name=pre_data[\"metadata\"][\"disaster\"]\n","            # fetch disaster type from metadata\n","            disaster_type=pre_data[\"metadata\"][\"disaster_type\"]\n","            # fetch pre-disaster image capture date from metadata\n","            pre_disaster_capture_date=datetime.fromisoformat(pre_data[\"metadata\"][\"capture_date\"][:-1])\n","            pre_disaster_capture_date=pre_disaster_capture_date.date()\n","            # fetch lng_lat features from features\n","            lang_lat_features=pre_data[\"features\"][\"lng_lat\"]\n","            # fetch number of buildings from features\n","            num_buildings_pre=len(pre_data[\"features\"][\"lng_lat\"])\n","            # if any buildings exist in the image\n","            if num_buildings_pre>0:\n","                # get centroid of the location\n","                location_coords=lang_lat_features[0][\"wkt\"]\n","                centroid =  Polygon(wkt.loads(location_coords)).centroid\n","                # get location of the centroid\n","                geolocator = Nominatim(user_agent=\"geo_locator\")\n","                location = geolocator.reverse((centroid.y, centroid.x))\n","                # get state/city and country from location\n","                if 'state' in location.raw['address']:\n","                    disaster_location = location.raw['address']['state'] + \", \" + location.raw['address']['country']\n","                else:\n","                    disaster_location = location.raw['address']['city'] + \", \" + location.raw['address']['country']\n","                disaster_location_info[disaster_name] = disaster_location\n","            # set disaster location to none if there are no buildings in the image\n","            else:\n","                disaster_location= None\n","        # read post-disaster json\n","        with open(post_json_filepath, 'r') as file:\n","            post_data = json.load(file)\n","            # fetch post-disaster image name from metadata\n","            post_image_name=post_data[\"metadata\"][\"img_name\"]\n","            # fetch post-disaster image capture date from metadata\n","            post_disaster_capture_date=datetime.fromisoformat(post_data[\"metadata\"][\"capture_date\"][:-1])\n","            post_disaster_capture_date=post_disaster_capture_date.date()\n","            # fetch building features from xy features\n","            building_features=post_data[\"features\"][\"xy\"]\n","            # count number of buildings from features\n","            num_buildings_post=len(building_features)\n","            # count number of buildings by damage type\n","            building_damage_info={\"no-damage\":0,\"minor-damage\":0,\"major-damage\":0,\"destroyed\":0,\"un-classified\":0}\n","            for feature in building_features:\n","                damage_type=feature[\"properties\"][\"subtype\"]\n","                building_damage_info[damage_type] += 1\n","            num_no_damage=building_damage_info[\"no-damage\"]\n","            num_minor_damage=building_damage_info[\"minor-damage\"]\n","            num_major_damage=building_damage_info[\"major-damage\"]\n","            num_destroyed=building_damage_info[\"destroyed\"]\n","            num_un_classified=building_damage_info[\"un-classified\"]\n","        # create dataframe row\n","        row_data = {\n","            \"pre_image_name\": pre_image_name,\n","            \"post_image_name\": post_image_name,\n","            \"disaster_name\": disaster_name,\n","            \"disaster_type\": disaster_type,\n","            \"disaster_location\": disaster_location,\n","            \"num_buildings_pre\": num_buildings_pre,\n","            \"num_buildings_post\": num_buildings_post,\n","            \"num_no_damage\": num_no_damage,\n","            \"num_minor_damage\": num_minor_damage,\n","            \"num_major_damage\": num_major_damage,\n","            \"num_destroyed\": num_destroyed,\n","            \"num_un_classified\": num_un_classified,\n","            \"pre_disaster_capture_date\": pre_disaster_capture_date,\n","            \"post_disaster_capture_date\": post_disaster_capture_date\n","        }\n","        # append row to dataframe\n","        df=pd.concat([df, pd.DataFrame([row_data])], ignore_index=True)"]},{"cell_type":"code","execution_count":null,"id":"yiqsUXmjHXRj","metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1714823896010,"user":{"displayName":"Yugandar Narra","userId":"14916928621674904417"},"user_tz":300},"id":"yiqsUXmjHXRj"},"outputs":[],"source":["#if any disaster location is null fill it with info from disaster_location_info\n","#run only if csv is not created\n","df.loc[df[\"disaster_location\"].isnull(), \"disaster_location\"] = df[\"disaster_name\"].map(disaster_location_info)"]},{"cell_type":"code","execution_count":null,"id":"rUnQPJXmbaM_","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1714823896010,"user":{"displayName":"Yugandar Narra","userId":"14916928621674904417"},"user_tz":300},"id":"rUnQPJXmbaM_","outputId":"841f43eb-d317-4cd0-f34e-aec376714f55"},"outputs":[],"source":["df[\"pre_disaster_capture_date\"][0],df[\"post_disaster_capture_date\"][0]"]},{"cell_type":"code","execution_count":null,"id":"r9LizBM8af_m","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":464},"executionInfo":{"elapsed":129,"status":"ok","timestamp":1714823974057,"user":{"displayName":"Yugandar Narra","userId":"14916928621674904417"},"user_tz":300},"id":"r9LizBM8af_m","outputId":"5be3a90e-14c7-4122-e968-b8bee798a72b"},"outputs":[],"source":["unique_dates = df.groupby('disaster_name')[['pre_disaster_capture_date', 'post_disaster_capture_date']].agg(pd.Series.unique)\n","unique_dates"]},{"cell_type":"code","execution_count":null,"id":"QvaaIdx0evZI","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":354},"executionInfo":{"elapsed":161,"status":"ok","timestamp":1714825123500,"user":{"displayName":"Yugandar Narra","userId":"14916928621674904417"},"user_tz":300},"id":"QvaaIdx0evZI","outputId":"cff65456-4235-4158-ce30-b9182f2c746f"},"outputs":[],"source":["df_capture_dates = df.groupby('disaster_name').agg({'pre_disaster_capture_date': lambda x: x.mode()[0], 'post_disaster_capture_date': lambda x: x.mode()[0]}).reset_index()\n","df_capture_dates['diff_in_years'] = ((df_capture_dates['post_disaster_capture_date'] - df_capture_dates['pre_disaster_capture_date']).dt.days / 365).round(1)\n","df_capture_dates"]},{"cell_type":"code","execution_count":null,"id":"f1a8418f-23bb-451a-aa83-ec6be355af1f","metadata":{"executionInfo":{"elapsed":141,"status":"ok","timestamp":1714824310219,"user":{"displayName":"Yugandar Narra","userId":"14916928621674904417"},"user_tz":300},"id":"f1a8418f-23bb-451a-aa83-ec6be355af1f"},"outputs":[],"source":["# save the dataframe to csv\n","# run only first time\n","df.to_csv(train_data_info, index=False)"]},{"cell_type":"code","execution_count":null,"id":"BojCuYjuU7pw","metadata":{"id":"BojCuYjuU7pw"},"outputs":[],"source":["# load the csv file if already created\n","csv_path = \"C:\\\\Users\\\\PC\\\\Desktop\\\\drac_saved_files\\\\train_data_info.csv\"\n","df = pd.read_csv(csv_path)"]},{"cell_type":"code","execution_count":null,"id":"JKAHuDXxaJVx","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":133,"status":"ok","timestamp":1714823082924,"user":{"displayName":"Yugandar Narra","userId":"14916928621674904417"},"user_tz":300},"id":"JKAHuDXxaJVx","outputId":"8998bf9c-ad4a-45e0-dc04-0019553f3232"},"outputs":[],"source":["df[\"post_disaster_capture_date\"].value_counts()"]},{"cell_type":"code","execution_count":null,"id":"bd827abb-0fe7-4a06-bf3e-5efc0a123267","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":149,"status":"ok","timestamp":1714822845056,"user":{"displayName":"Yugandar Narra","userId":"14916928621674904417"},"user_tz":300},"id":"bd827abb-0fe7-4a06-bf3e-5efc0a123267","outputId":"60b6f0c3-c0ad-4f91-c42a-40631fc01365"},"outputs":[],"source":["df.info()"]},{"cell_type":"markdown","id":"RNtAmhf4U0Y9","metadata":{"id":"RNtAmhf4U0Y9"},"source":[]},{"cell_type":"code","execution_count":null,"id":"V6rx6zc2awQK","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":139,"status":"ok","timestamp":1714789503920,"user":{"displayName":"Yugandar Narra","userId":"14916928621674904417"},"user_tz":300},"id":"V6rx6zc2awQK","outputId":"8aea9deb-7006-4415-ee67-1e93d3c2ff13"},"outputs":[],"source":["# fetch all disaster events in the df\n","df[\"disaster_name\"].unique()"]},{"cell_type":"code","execution_count":null,"id":"d59963ee-277a-4bf8-bce4-367262822e2f","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1714789521836,"user":{"displayName":"Yugandar Narra","userId":"14916928621674904417"},"user_tz":300},"id":"d59963ee-277a-4bf8-bce4-367262822e2f","outputId":"9c25431f-0057-42b4-9aa8-eca22801c1b2"},"outputs":[],"source":["#check if there are any null values\n","df.isnull().any()"]},{"cell_type":"code","execution_count":null,"id":"e1751247-7da1-45cb-8e01-fc64e30a8457","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":313},"executionInfo":{"elapsed":133,"status":"ok","timestamp":1714789524399,"user":{"displayName":"Yugandar Narra","userId":"14916928621674904417"},"user_tz":300},"id":"e1751247-7da1-45cb-8e01-fc64e30a8457","outputId":"8f9fa886-3121-447b-f5c5-2969fd49ef03"},"outputs":[],"source":["df.head()"]},{"cell_type":"code","execution_count":null,"id":"R_-13gQ4DHah","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":607},"executionInfo":{"elapsed":4546,"status":"ok","timestamp":1714652354476,"user":{"displayName":"Yugandar Narra","userId":"14916928621674904417"},"user_tz":300},"id":"R_-13gQ4DHah","outputId":"21540864-8310-4c61-a53d-0cfafce36cc9"},"outputs":[],"source":["# plot number of image pairs per disaster type\n","plt.figure(figsize=(10, 6))\n","df.groupby('disaster_type').size().plot(kind='bar', color=sns.palettes.mpl_palette('Dark2'))\n","plt.title('Number of image pairs by disaster type')\n","plt.xlabel('Disaster')\n","plt.ylabel('Number of images')\n","plt.xticks(rotation=45, ha='right')\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"cd292f63-f437-4be0-9af5-9e78fec49880","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":73},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1714652354476,"user":{"displayName":"Yugandar Narra","userId":"14916928621674904417"},"user_tz":300},"id":"cd292f63-f437-4be0-9af5-9e78fec49880","outputId":"eac260db-99b0-4d26-e6e6-47a16b3eaf27"},"outputs":[],"source":["# check if any columns have different number of buildings pre and post disaster\n","df[df['num_buildings_pre'] != df['num_buildings_post']]"]},{"cell_type":"code","execution_count":null,"id":"luc6DLutVkg9","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":394},"executionInfo":{"elapsed":155,"status":"ok","timestamp":1714789564920,"user":{"displayName":"Yugandar Narra","userId":"14916928621674904417"},"user_tz":300},"id":"luc6DLutVkg9","outputId":"39a41521-89de-4c82-d61c-21c7648e2b3e"},"outputs":[],"source":["# Disaster event name along with disaster location and disaster type\n","df.groupby('disaster_name')[['disaster_location','disaster_type']].first()"]},{"cell_type":"code","execution_count":null,"id":"0e2ddecf-251e-4d29-9bb7-a68f5048042a","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":168,"status":"ok","timestamp":1714652665443,"user":{"displayName":"Yugandar Narra","userId":"14916928621674904417"},"user_tz":300},"id":"0e2ddecf-251e-4d29-9bb7-a68f5048042a","outputId":"96cd5357-64fe-4351-b68d-8f84c6a7f668"},"outputs":[],"source":["# Number of image pairs per disaster event\n","num_images_by_disaster=df[\"disaster_name\"].value_counts()\n","num_images_by_disaster"]},{"cell_type":"code","execution_count":null,"id":"344e4l_uUpIy","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":179,"status":"ok","timestamp":1714652663637,"user":{"displayName":"Yugandar Narra","userId":"14916928621674904417"},"user_tz":300},"id":"344e4l_uUpIy","outputId":"f45f4b63-afc9-42dd-a849-2ffec14d22a0"},"outputs":[],"source":["# number of buildings from all image pairs per disaster event\n","num_buildings_by_disaster=df.groupby('disaster_name')['num_buildings_pre'].sum()\n","num_buildings_by_disaster"]},{"cell_type":"code","execution_count":null,"id":"yt0sTl2uQ15K","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":394},"executionInfo":{"elapsed":135,"status":"ok","timestamp":1714652770277,"user":{"displayName":"Yugandar Narra","userId":"14916928621674904417"},"user_tz":300},"id":"yt0sTl2uQ15K","outputId":"4796d7ec-81ce-4847-caeb-b303926cb0d1"},"outputs":[],"source":["# number of images and buildings per disaster event\n","combined_table = pd.concat([num_images_by_disaster, num_buildings_by_disaster], axis=1)\n","combined_table.columns = ['Num_Images', 'Num_Buildings']\n","combined_table"]},{"cell_type":"code","execution_count":null,"id":"v2XUbRFCVfPb","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":607},"executionInfo":{"elapsed":571,"status":"ok","timestamp":1714652421489,"user":{"displayName":"Yugandar Narra","userId":"14916928621674904417"},"user_tz":300},"id":"v2XUbRFCVfPb","outputId":"783106be-51dd-4a72-c916-a8fcc49fb6db"},"outputs":[],"source":["# plot number of buildings per disaster event\n","plt.figure(figsize=(10, 6))\n","num_buildings_by_disaster.plot(kind='bar', color=sns.palettes.mpl_palette('Dark2'))\n","plt.title('Number of buildings Grouped by disaster_name')\n","plt.xlabel('Disaster Name')\n","plt.ylabel('Number of buildings')\n","plt.xticks(rotation=45, ha='right')\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"kdrxJazmyZyp","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":607},"executionInfo":{"elapsed":1364,"status":"ok","timestamp":1714652437622,"user":{"displayName":"Yugandar Narra","userId":"14916928621674904417"},"user_tz":300},"id":"kdrxJazmyZyp","outputId":"404a73f1-3073-452a-99e6-18ce8be54c45"},"outputs":[],"source":["# plot number of buildings and images comparision\n","combined_data = pd.DataFrame({\"Number of Images\": num_images_by_disaster,\n","                              \"Number of Buildings\": num_buildings_by_disaster})\n","\n","ax = combined_data.plot(kind='bar', figsize=(10, 6), color=['skyblue', 'orange'])\n","ax.set_title('Number of Images and Buildings Grouped by Disaster Name')\n","ax.set_xlabel('Disaster Name')\n","ax.set_ylabel('Count')\n","ax.tick_params(axis='x', rotation=45)\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"P5FHTSbpni8o","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":394},"executionInfo":{"elapsed":154,"status":"ok","timestamp":1714793062233,"user":{"displayName":"Yugandar Narra","userId":"14916928621674904417"},"user_tz":300},"id":"P5FHTSbpni8o","outputId":"9d051a3e-1d37-45dd-f1e4-7cd56ff7082b"},"outputs":[],"source":["damage_counts_by_disaster = df.groupby(\"disaster_name\")[[\"num_no_damage\", \"num_minor_damage\", \"num_major_damage\", \"num_destroyed\"]].sum()\n","damage_counts_by_disaster"]},{"cell_type":"code","execution_count":null,"id":"OOAYPeDTxZgV","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":607},"executionInfo":{"elapsed":829,"status":"ok","timestamp":1714790097498,"user":{"displayName":"Yugandar Narra","userId":"14916928621674904417"},"user_tz":300},"id":"OOAYPeDTxZgV","outputId":"172a5cdf-3f05-4b6c-e3d0-0e564fb8d1fe"},"outputs":[],"source":["custom_colors = ['green', 'blue', 'orange', 'red']\n","damage_counts_by_disaster.plot(kind='bar', stacked=True, figsize=(10, 6), color=custom_colors)\n","plt.title('Number of Buildings with Different Damage Levels Grouped by Disaster Name')\n","plt.xlabel('Disaster Name')\n","plt.ylabel('Count')\n","plt.xticks(rotation=45, ha='right')\n","plt.legend(title='Damage Level')\n","\n","# Show the plot\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"a1edd81c-3ba0-4a40-bcc0-c5d0dc862c3a","metadata":{"id":"a1edd81c-3ba0-4a40-bcc0-c5d0dc862c3a","outputId":"0b99929b-c4df-4faa-e611-029ba5a7afb4"},"outputs":[],"source":["disaster_names=list(df[\"disaster_name\"].unique())\n","disaster_names"]},{"cell_type":"code","execution_count":null,"id":"Pm4muPykTEWg","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":121},"executionInfo":{"elapsed":154,"status":"ok","timestamp":1714653482160,"user":{"displayName":"Yugandar Narra","userId":"14916928621674904417"},"user_tz":300},"id":"Pm4muPykTEWg","outputId":"0eed14a3-c2da-48c8-faf8-45f1f152d9ef"},"outputs":[],"source":["temp1=wkt.loads(\"POLYGON ((-79.03585510827186 33.60387497715141, -79.03582104187559 33.60388575665863, -79.03582375650119 33.60389388588764, -79.03569553047664 33.60392338512618, -79.03564470548032 33.60386354920797, -79.03563977720466 33.6037826097889, -79.03578743284996 33.6037485675312, -79.03580478400323 33.60375046033562, -79.03585510827186 33.60387497715141))\")\n","temp1"]},{"cell_type":"code","execution_count":null,"id":"bB0I1mj8TSBp","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1714653480115,"user":{"displayName":"Yugandar Narra","userId":"14916928621674904417"},"user_tz":300},"id":"bB0I1mj8TSBp","outputId":"dacfd4f8-f67d-4fd5-d0f4-1ddc8cc3a1e7"},"outputs":[],"source":["import numpy as np\n","from shapely.geometry import Point, Polygon, mapping\n","temp2 = list(mapping(temp1)['coordinates'][0])\n","temp3 = np.array(temp2, np.int32)\n","temp2,temp3"]},{"cell_type":"code","execution_count":null,"id":"2003165c-4723-4788-94ea-72a91d83654d","metadata":{"id":"2003165c-4723-4788-94ea-72a91d83654d"},"outputs":[],"source":["import cv2\n","import numpy as np\n","from shapely import wkt\n","from shapely.geometry import mapping, Polygon\n","from skimage.io import imread\n","\n","# Create the Polygon Mask files using the labels\n","# takes mask size(height and width) and polygon vertices\n","def generate_polygon_masks(mask_size, polys):\n","    # shrink the polygon vertices by 2 pixels\n","    shrink=2\n","    # initialize mask array and fill with 0\n","    mask = np.zeros(mask_size, np.uint8)\n","    # iterate over all building polygons in the image\n","    for i in polys:\n","        # get the polygon vertices\n","        poly = polys[i]\n","        # create shapely polygon object for the building\n","        polygon = Polygon(poly)\n","        # calculate centroid of the polygon\n","        (centroid_x, centroid_y) = polygon.centroid.coords[0]\n","        shrunk_polygon = []\n","        # iterate over the exterior coordinates\n","        for (x,y) in polygon.exterior.coords:\n","            # shrink the polygon by 2 pixels on all sides\n","            x += shrink if x < centroid_x else -shrink if x > centroid_x else 0\n","            y += shrink if y < centroid_y else -shrink if y > centroid_y else 0\n","            shrunk_polygon.append([x,y])\n","        temp=np.zeros(mask_size, np.uint8)\n","        # fill the polygon area with white color\n","        cv2.fillPoly(temp, [np.array(shrunk_polygon, np.int32)], (1, 1, 1))\n","        mask += temp\n","    # convert the mask to binary where white pixels represent the polygon areas.\n","    mask[mask > 1] = 0\n","    mask[mask == 1] = 255\n","    return mask"]},{"cell_type":"code","execution_count":null,"id":"JfhiYXRm7YvW","metadata":{"id":"JfhiYXRm7YvW","outputId":"bfaffd9d-e9fb-42b4-e983-1c04dfafbb15"},"outputs":[],"source":["pre_image_names=[]\n","# Create the full path to the images, labels, and mask output directories\n","print(f\"Starting Mask Generation\")\n","print(f\"Source Image Directory: {images_dir} \\nSource JSON Directory: {labels_dir}\\nOutput Directory: {masks_dir}\")\n","#Get the list of pre-disaster json files\n","labels_pre = []\n","for file_name in os.listdir(labels_dir):\n","    # consider only pre disaster labels\n","    if '_pre' in file_name:\n","        labels_pre.append(file_name)\n","img_count=0\n","label_count=0\n","mask_count=0\n","images_without_buildings_count=0\n","# generate masks using pre disaster labels\n","for label_file in labels_pre:\n","    # Configure source image and generated mask names and paths\n","    image_name = os.path.splitext(label_file)[0] + '.png'\n","    pre_image_names.append(image_name)\n","    mask_file_name = image_name\n","    label_full_path = os.path.join(labels_dir, label_file)\n","    # Read Data From label JSON file\n","    mask_json = json.load(open(label_full_path))\n","    label_count+=1\n","    # Read Image File\n","    image_file = os.path.join(images_dir, image_name)\n","    img = cv2.imread(image_file)\n","    img = np.array(img)\n","    # mask size is same as image size\n","    mask_size = img.shape\n","    img_count+=1\n","    # Read Building Features from Json\n","    polys = {}\n","    for feature in mask_json['features']['xy']:\n","        # extract building shape in wkt format from json and convert to shapely object\n","        building_shape = wkt.loads(feature['wkt'])\n","        # extract building vertices/co-ordinates from shapely object\n","        coords = list(mapping(building_shape)['coordinates'][0])\n","        # store co-ordinates to polys dictionary with building id as key\n","        polys[feature['properties']['uid']] = (np.array(coords, np.int32))\n","    # check if there are any buildings in the image\n","    if len(polys) >= 0:\n","        # generate mask using polygon vertices\n","        masked_polys = generate_polygon_masks(mask_size, polys)\n","        # configure mask file path\n","        mask_file_path = os.path.join(masks_dir, mask_file_name)\n","        # save mask image\n","        cv2.imwrite(mask_file_path, masked_polys)\n","        mask_count+=1\n","    else:\n","        images_without_buildings_count+=1\n","print(\"Images checked: \",img_count)\n","print(\"Labels checked: \",label_count)\n","print(\"Masks Generated: \",mask_count)\n","print(\"Images Without Buildings: \",images_without_buildings_count)\n","print(\"Mask Generation Complete\")"]},{"cell_type":"code","execution_count":null,"id":"2ea72129-f56f-4802-be8e-1df9d9610960","metadata":{"id":"2ea72129-f56f-4802-be8e-1df9d9610960"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","#Split data into train and test\n","mask_image_names=os.listdir(masks_dir)\n","train_set, test_set = train_test_split(pre_image_names, test_size=0.25, random_state=42)\n","# save train image names to train.txt and test to test.txt\n","train_file_path=os.path.join(extracted_files,\"train.txt\")\n","test_file_path=os.path.join(extracted_files,\"test.txt\")\n","\n","# Write the train set to train.txt\n","with open(train_file_path, \"w\") as train_file:\n","    train_file.write(\"\\n\".join(train_set))\n","\n","# Write the test set to test.txt\n","with open(test_file_path, \"w\") as test_file:\n","    test_file.write(\"\\n\".join(test_set))"]},{"cell_type":"code","execution_count":null,"id":"7dbb52a3-d2fd-481a-88c7-bcdda86067fc","metadata":{"id":"7dbb52a3-d2fd-481a-88c7-bcdda86067fc"},"outputs":[],"source":["from PIL import Image\n","# Generate mean.npy for Localization Model\n","mean_file=os.path.join(extracted_files,\"mean.npy\")\n","\n","N = len(pre_image_names)\n","sum_color = np.zeros((3,))\n","\n","# Compute mean image\n","for i, image_name in enumerate(mask_image_names):\n","    with Image.open(os.path.join(images_dir, image_name)) as image_file:\n","        image = np.asarray(image_file, dtype=np.float64)\n","    sum_color += np.mean(image, axis=(0, 1))\n","\n","mean = sum_color / N\n","\n","# Save mean in npy format\n","np.save(mean_file, mean)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"drac_baseline","language":"python","name":"drac_baseline"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":5}
